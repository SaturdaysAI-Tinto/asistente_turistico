{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ast\n",
    "import nltk\n",
    "import re\n",
    "import unidecode\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subir un directorio\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/places_reviews_processed.csv')\n",
    "df_1 = pd.read_csv('data/places_types.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['place_id', 'url', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_1, how='left', on='place_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Museo', 'Comida mexicana', 'Templo', 'Teatro', 'Ecoturismo',\n",
       "       'Pirámides'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tipo_lugar'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temática: Restaurantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurantes = df[df['tipo_lugar']=='Comida mexicana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = restaurantes.text\n",
    "data_corpus = restaurantes[['place_id', 'url']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpiar el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doClean(text):   \n",
    "    \n",
    "    # Quitar las expresiones entre llaves que denotan las partes de la canción\n",
    "    a = re.sub(r'\\[.+\\]', ' ', str(text))\n",
    "    # Quitar las aclaraciones entre paréntesis\n",
    "    a = re.sub(r'\\(.+\\)', ' ', str(a))\n",
    "    # Quitar acentos \n",
    "    a = unidecode.unidecode(a)\n",
    "    # Quitar aquello que no sean palabras o cosa que se le parezca\n",
    "    a = re.sub(r'\\W', ' ', a)\n",
    "    # Quitar espacios extra en caso de haber\n",
    "    a = re.sub(r'\\s+', ' ', a, flags=re.I)\n",
    "    # Pasar el texto a minúsulas\n",
    "    a = a.lower()\n",
    "    # retirar stopwords\n",
    "    a = a.split()\n",
    "    a = [ word for word in a if word not in stopwords.words('spanish')]\n",
    "    a = \" \".join(a)\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_clean = corpus.apply(doClean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tv = TfidfVectorizer(min_df=0., max_df=.9, use_idf=True, max_features=300)\n",
    "tv_matrix = tv.fit_transform(corpus_clean)\n",
    "tv_matrix = tv_matrix.toarray()\n",
    "\n",
    "vocab = tv.get_feature_names()\n",
    "prueba = pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteo de veces que aparecen palabras claves\n",
    "comida_words = ['buen', 'buena', 'buenas', 'bueno', 'buenos', 'calidad', 'delicia', 'deliciosa', 'deliciosas',\n",
    "                'delicioso', 'deliciosos', 'delicious', 'exquisito', 'presentacion', 'rica', 'ricas',\n",
    "                'rico', 'ricos', 'riquisima', 'riquisimo', 'sabor', 'sabores', 'sabroso', 'sazon']\n",
    "servicio_words = ['amable', 'amables', 'atencion', 'atento', 'atentos', 'atienden', 'limpieza', 'higiene', \n",
    "                 'limpio', 'rapido', 'service', 'servicio']\n",
    "ambiente_words = ['acogedor', 'agradable', 'ambiente', 'bonito', 'decoracion', \n",
    "                  'familiar', 'musica', 'tranquilo']\n",
    "satisfaccion_words = ['encanta', 'encanto', 'espectacular', 'especial', 'espectacular', 'excelente',\n",
    "                      'excelentes', 'exelente', 'good', 'great', 'increible', 'nice', 'recomendable',\n",
    "                     'recomendable', 'recomendado', 'recomiendo']\n",
    "specials_words = ['barbacoa', 'birria', 'carne', 'carnitas', 'chocolate', 'cochinita', 'enchiladas', \n",
    "                  'mariscos', 'mole', 'nogada', 'pozole', 'tacos', 'tortas', \n",
    "                 'yucateca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_clean_df = pd.DataFrame(corpus_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reser index \n",
    "corpus_clean_df = corpus_clean_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_clean_df_2 = corpus_clean_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columnas\n",
    "corpus_clean_df_2['comida'] = float('nan')\n",
    "corpus_clean_df_2['servicio'] = float('nan')\n",
    "corpus_clean_df_2['ambiente'] = float('nan')\n",
    "corpus_clean_df_2['satisfaccion'] = float('nan')\n",
    "corpus_clean_df_2['specials'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(corpus_clean_df)):\n",
    "    res = corpus_clean_df['text'][i].split()\n",
    "    #Counters\n",
    "    comida_counter = 0\n",
    "    service_counter = 0\n",
    "    ambiente_counter = 0\n",
    "    satisfaccion_counter = 0\n",
    "    specials = []\n",
    "    for j in res:\n",
    "        if j in comida_words:\n",
    "            comida_counter = comida_counter+1\n",
    "        if j in servicio_words:\n",
    "            service_counter = service_counter+1\n",
    "        if j in ambiente_words:\n",
    "            ambiente_counter = ambiente_counter+1\n",
    "        if j in satisfaccion_words:\n",
    "            satisfaccion_counter = satisfaccion_counter+1\n",
    "        if j in specials_words:\n",
    "            specials.append(j)\n",
    "    \n",
    "    #Asignar valores\n",
    "    corpus_clean_df_2.iloc[i, corpus_clean_df_2.columns.get_loc('comida')] = comida_counter\n",
    "    corpus_clean_df_2.iloc[i, corpus_clean_df_2.columns.get_loc('servicio')] = service_counter\n",
    "    corpus_clean_df_2.iloc[i, corpus_clean_df_2.columns.get_loc('ambiente')] = ambiente_counter\n",
    "    corpus_clean_df_2.iloc[i, corpus_clean_df_2.columns.get_loc('satisfaccion')] = satisfaccion_counter\n",
    "    \n",
    "    specials_concatenation = '-'.join(specials)\n",
    "    corpus_clean_df_2.iloc[i, corpus_clean_df_2.columns.get_loc('specials')] = specials_concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir con datos de los restaurantes\n",
    "corpus_clean_df_2 = corpus_clean_df_2.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurantes_final = pd.merge(data_corpus, corpus_clean_df_2, how='left', left_index=True,\n",
    "                              right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupar a nivel restaurante "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurantes_final_2 = pd.DataFrame()\n",
    "place_id = restaurantes_final['place_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in place_id:\n",
    "    df_temp = restaurantes_final[restaurantes_final['place_id']==i]\n",
    "    df_temp_2 = df_temp.copy()\n",
    "    \n",
    "    df_temp_2_grouped = df_temp_2.groupby('place_id').agg({'url':'count',\n",
    "                                                           'comida':'sum',\n",
    "                                                           'servicio':'sum',\n",
    "                                                           'ambiente':'sum',\n",
    "                                                           'satisfaccion':'sum',\n",
    "                                                          })\n",
    "    \n",
    "    temp_list = []\n",
    "    for j in df_temp_2['specials']:\n",
    "        if j == '':\n",
    "            None\n",
    "        else:\n",
    "            temp_list.append(j)\n",
    "    #Separar los specials\n",
    "    temp = []\n",
    "    for element in temp_list:\n",
    "        splitted = element.split(\"-\")\n",
    "        for word in splitted:\n",
    "            temp.append(word)\n",
    "    #Obtener specials únicos\n",
    "    myset = set(temp)\n",
    "    specials_uniques = list(myset)\n",
    "    #Concatenar en un sólo string\n",
    "    specials_uniques_concatenation = '-'.join(specials_uniques)\n",
    "    #Crear variable\n",
    "    df_temp_2_grouped['specials'] = specials_uniques_concatenation\n",
    "    \n",
    "    restaurantes_final_2 = pd.concat([restaurantes_final_2, df_temp_2_grouped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurantes_final_2 = restaurantes_final_2.rename(columns={'url': 'conteo_reviews'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurantes_final_2['comida_norm'] = restaurantes_final_2['comida']/restaurantes_final_2['conteo_reviews']\n",
    "restaurantes_final_2['servicio_norm'] = restaurantes_final_2['servicio']/restaurantes_final_2['conteo_reviews']\n",
    "restaurantes_final_2['ambiente_norm'] = restaurantes_final_2['ambiente']/restaurantes_final_2['conteo_reviews']\n",
    "restaurantes_final_2['satisfaccion_norm'] = restaurantes_final_2['satisfaccion']/restaurantes_final_2['conteo_reviews']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurantes_final_2.to_csv('data/restaurants_classification.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ecoturismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoturismo = df[df['tipo_lugar']=='Ecoturismo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ecoturismo.text\n",
    "data_corpus = ecoturismo[['place_id', 'url']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpiar texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_clean = corpus.apply(doClean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(min_df=0., max_df=.7, use_idf=True, max_features=200)\n",
    "tv_matrix = tv.fit_transform(corpus_clean)\n",
    "tv_matrix = tv_matrix.toarray()\n",
    "\n",
    "vocab = tv.get_feature_names()\n",
    "prueba = pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear diccionario\n",
    "actividades = ['acampar','actividades', 'alimentos','animales','atracciones','bici','bicicleta','cabanas'\n",
    "               'correr','divertido','ejercicio', 'instalaciones','juegos','lago', 'pasear','tirolesa']\n",
    "recomendado = ['agradable','amable', 'atencion','bello','bello', 'bien','bonito','buena', 'buenas',\n",
    "               'bueno','buenos', 'calidad','disfrutar','encanta', 'encanto', 'excelente', 'exelente',\n",
    "              'genial','great','gusta', 'gusto','hermosa','hermoso', 'increible','lindo',\n",
    "               'magico', 'maravilloso','perfecto', 'recomendable','recomendado', 'recomiendo','servicio']\n",
    "naturaleza = ['amplio','bosque', 'cabanas','caminar','correr', 'familia','familiar','fresco', \n",
    "              'grande','lago','naturaleza', 'natural','paisaje','paisajes', 'parque','peces','relajarse']\n",
    "specials_words = ['acampar','animales', 'bici','bicicleta','cabanas', 'lago','peces','tirolesa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_clean_df = pd.DataFrame(corpus_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reser index \n",
    "corpus_clean_df = corpus_clean_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_clean_df_2 = corpus_clean_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columnas\n",
    "corpus_clean_df_2['actividades'] = float('nan')\n",
    "corpus_clean_df_2['recomendado'] = float('nan')\n",
    "corpus_clean_df_2['naturaleza'] = float('nan')\n",
    "corpus_clean_df_2['specials'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(corpus_clean_df)):\n",
    "    res = corpus_clean_df['text'][i].split()\n",
    "    #Counters\n",
    "    counter_1 = 0\n",
    "    counter_2 = 0\n",
    "    counter_3 = 0\n",
    "    specials = []\n",
    "    for j in res:\n",
    "        if j in actividades:\n",
    "            counter_1 = counter_1+1\n",
    "        if j in recomendado:\n",
    "            counter_2 = counter_2+1\n",
    "        if j in naturaleza:\n",
    "            counter_3 = counter_3+1\n",
    "        if j in specials_words:\n",
    "            specials.append(j)\n",
    "    \n",
    "    #Asignar valores\n",
    "    corpus_clean_df_2.iloc[i, corpus_clean_df_2.columns.get_loc('actividades')] = counter_1\n",
    "    corpus_clean_df_2.iloc[i, corpus_clean_df_2.columns.get_loc('recomendado')] = counter_2\n",
    "    corpus_clean_df_2.iloc[i, corpus_clean_df_2.columns.get_loc('naturaleza')] = counter_3\n",
    "    \n",
    "    specials_concatenation = '-'.join(specials)\n",
    "    corpus_clean_df_2.iloc[i, corpus_clean_df_2.columns.get_loc('specials')] = specials_concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir con datos de los lugares\n",
    "corpus_clean_df_2 = corpus_clean_df_2.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoturismo_final = pd.merge(data_corpus, corpus_clean_df_2, how='left', left_index=True,\n",
    "                              right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agrupar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoturismo_final_2 = pd.DataFrame()\n",
    "place_id = ecoturismo_final['place_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in place_id:\n",
    "    df_temp = ecoturismo_final[ecoturismo_final['place_id']==i]\n",
    "    df_temp_2 = df_temp.copy()\n",
    "    \n",
    "    df_temp_2_grouped = df_temp_2.groupby('place_id').agg({'url':'count',\n",
    "                                                           'actividades':'sum',\n",
    "                                                           'recomendado':'sum',\n",
    "                                                           'naturaleza':'sum'\n",
    "                                                          })\n",
    "    \n",
    "    temp_list = []\n",
    "    for j in df_temp_2['specials']:\n",
    "        if j == '':\n",
    "            None\n",
    "        else:\n",
    "            temp_list.append(j)\n",
    "    #Separar los specials\n",
    "    temp = []\n",
    "    for element in temp_list:\n",
    "        splitted = element.split(\"-\")\n",
    "        for word in splitted:\n",
    "            temp.append(word)\n",
    "    #Obtener specials únicos\n",
    "    myset = set(temp)\n",
    "    specials_uniques = list(myset)\n",
    "    #Concatenar en un sólo string\n",
    "    specials_uniques_concatenation = '-'.join(specials_uniques)\n",
    "    #Crear variable\n",
    "    df_temp_2_grouped['specials'] = specials_uniques_concatenation\n",
    "    \n",
    "    ecoturismo_final_2 = pd.concat([ecoturismo_final_2, df_temp_2_grouped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoturismo_final_2 = ecoturismo_final_2.rename(columns={'url': 'conteo_reviews'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar\n",
    "ecoturismo_final_2['actividades_norm'] = ecoturismo_final_2['actividades']/ecoturismo_final_2['conteo_reviews']\n",
    "ecoturismo_final_2['recomendado_norm'] = ecoturismo_final_2['recomendado']/ecoturismo_final_2['conteo_reviews']\n",
    "ecoturismo_final_2['naturaleza_norm'] = ecoturismo_final_2['naturaleza']/ecoturismo_final_2['conteo_reviews']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoturismo_final_2.to_csv('data/ecoturismo_classification.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cultural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = ['Museo', 'Templo', 'Teatro', 'Pirámides']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "cultural = df[df['tipo_lugar'].isin(list_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = cultural.text\n",
    "data_corpus = cultural[['place_id', 'url']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpiar texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_clean = corpus.apply(doClean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(min_df=0., max_df=.5, use_idf=True, max_features=250)\n",
    "tv_matrix = tv.fit_transform(corpus_clean)\n",
    "tv_matrix = tv_matrix.toarray()\n",
    "\n",
    "vocab = tv.get_feature_names()\n",
    "prueba = pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear diccionario\n",
    "ambiente = ['acogedor', 'agradable', 'amable', 'amables', 'ambiente', 'atencion', 'comodo', 'disfrutar',\n",
    "            'divertido', 'entretenido', 'interesante', 'interesantes', 'limpio', 'servicio', '', '', '', \n",
    "           'tranquilo', '', '', '', '', '', ]\n",
    "recomendable = ['apreciar', 'bello', 'bien', 'bonita', 'bonito', 'buena', 'buenas', 'bueno', 'buenos',\n",
    "                'calidad', 'encanta', 'encanto', 'espectacular', 'excelente', 'excelentes','exelente',\n",
    "                'genial', 'hermosa','hermoso', 'impresionante', 'increible','lindo', 'maravilloso', 'perfecto', \n",
    "               'precios', 'precioso','recomendable', 'recomendado','recomiendo', '', '', '', '',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_clean_df = pd.DataFrame(corpus_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reser index \n",
    "corpus_clean_df = corpus_clean_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_clean_df_2 = corpus_clean_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columnas\n",
    "corpus_clean_df_2['ambiente'] = float('nan')\n",
    "corpus_clean_df_2['recomendable'] = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(corpus_clean_df)):\n",
    "    res = corpus_clean_df['text'][i].split()\n",
    "    #Counters\n",
    "    counter_1 = 0\n",
    "    counter_2 = 0\n",
    "    for j in res:\n",
    "        if j in ambiente:\n",
    "            counter_1 = counter_1+1\n",
    "        if j in recomendable:\n",
    "            counter_2 = counter_2+1\n",
    "    \n",
    "    #Asignar valores\n",
    "    corpus_clean_df_2.iloc[i, corpus_clean_df_2.columns.get_loc('ambiente')] = counter_1\n",
    "    corpus_clean_df_2.iloc[i, corpus_clean_df_2.columns.get_loc('recomendable')] = counter_2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir con datos de los lugares\n",
    "corpus_clean_df_2 = corpus_clean_df_2.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "cultural_final = pd.merge(data_corpus, corpus_clean_df_2, how='left', left_index=True,\n",
    "                              right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agrupar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "cultural_final_2 = pd.DataFrame()\n",
    "place_id = cultural_final['place_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in place_id:\n",
    "    df_temp = cultural_final[cultural_final['place_id']==i]\n",
    "    df_temp_2 = df_temp.copy()\n",
    "    \n",
    "    df_temp_2_grouped = df_temp_2.groupby('place_id').agg({'url':'count',\n",
    "                                                           'ambiente':'sum',\n",
    "                                                           'recomendable':'sum'\n",
    "                                                          })\n",
    "\n",
    "    \n",
    "    cultural_final_2 = pd.concat([cultural_final_2, df_temp_2_grouped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "cultural_final_2 = cultural_final_2.rename(columns={'url': 'conteo_reviews'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar\n",
    "cultural_final_2['ambiente_norm'] = cultural_final_2['ambiente']/cultural_final_2['conteo_reviews']\n",
    "cultural_final_2['recomendable_norm'] = cultural_final_2['recomendable']/cultural_final_2['conteo_reviews']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "cultural_final_2.to_csv('data/cultural_classification.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
